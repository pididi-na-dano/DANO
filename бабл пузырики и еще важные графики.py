import pandas as pd

sdel=pd.read_excel("–°–¥–µ–ª–∫–∏_2025-11-25.xlsx")
proj=pd.read_excel("–ü—Ä–æ–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ_2025-11-25.xlsx")

import pandas as pd
import numpy as np

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
IQR_THRESHOLD = 1.5
MIN_PRICE_UNIT = 1_000_000

# === 0. –ü–û–î–ì–û–¢–û–í–ö–ê –ò –ë–ï–ó–û–ü–ê–°–ù–û–ï –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï (–ß–¢–û–ë–´ –ù–ê–ô–¢–ò –î–ê–¢–£ –°–¢–ê–†–¢–ê) ===
sdel_clean = sdel.copy()
proj_clean = proj.copy()

# –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ —Å –¥–∞—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º –Ω—É–∂–Ω—ã
col_dogovor = '–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ (–º–µ—Å—è—Ü.–≥–æ–¥)'
col_reg = '–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ (–º–µ—Å—è—Ü.–≥–æ–¥)'
col_start = '–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø—Ä–æ–µ–∫—Ç–∞' # <--- –ü–†–û–í–ï–†–¨, –ß–¢–û –í –¢–ê–ë–õ–ò–¶–ï PROJ –û–ù–ê –ù–ê–ó–´–í–ê–ï–¢–°–Ø –¢–ê–ö –ñ–ï!

# –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–∞—Ç—É —Å—Ç–∞—Ä—Ç–∞. –ï—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ —Å–¥–µ–ª–∫–∞—Ö, —Ç–∞—â–∏–º –∏–∑ –ø—Ä–æ–µ–∫—Ç–æ–≤
if col_start not in sdel_clean.columns:
    if col_start in proj_clean.columns:
        # –ò—â–µ–º –∫–ª—é—á –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ —ç—Ç–æ ID –ø—Ä–æ–µ–∫—Ç–∞)
        # –ü—Ä–æ–±—É–µ–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: 'ID –ø—Ä–æ–µ–∫—Ç–∞', 'id_project', 'ID_PROJ'
        merge_keys = [k for k in ['ID –ø—Ä–æ–µ–∫—Ç–∞', 'ID_–ø—Ä–æ–µ–∫—Ç–∞', 'id_project'] if k in sdel_clean.columns and k in proj_clean.columns]
        
        if merge_keys:
            print(f"‚úÖ –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º '{col_start}' –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –∫–ª—é—á—É: {merge_keys[0]}...")
            sdel_clean = sdel_clean.merge(proj_clean[[merge_keys[0], col_start]], on=merge_keys[0], how='left')
        else:
            print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ –Ω–∞—à–µ–ª –æ–±—â–∏–π ID –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü. '{col_start}' –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å!")
    else:
        print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ö–æ–ª–æ–Ω–∫–∏ '{col_start}' –Ω–µ—Ç –Ω–∏ –≤ —Å–¥–µ–ª–∫–∞—Ö, –Ω–∏ –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–∑–≤–∞–Ω–∏–µ!")

# === 1. –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê (ETL) ===
def clean_numeric_col(df, col_name):
    if col_name in df.columns:
        val = df[col_name].astype(str)
        val = val.str.replace("\u00a0", "").str.replace(" ", "").str.replace(",", ".")
        return pd.to_numeric(val, errors="coerce").fillna(0)
    return df[col_name] if col_name in df.columns else 0

# –û—á–∏—Å—Ç–∫–∞ —á–∏—Å–µ–ª
target_cols = ['–°—É–º–º–∞ –±—é–¥–∂–µ—Ç–∞', '–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫', '–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫', 
               '–≠—Ç–∞–∂ –ª–æ—Ç–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç']
for col in target_cols:
    sdel_clean[col] = clean_numeric_col(sdel_clean, col)

# === –û–ß–ò–°–¢–ö–ê –î–ê–¢ (–°–ê–ú–û–ï –í–ê–ñ–ù–û–ï) ===
# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
all_date_cols = [c for c in [col_dogovor, col_reg, col_start] if c in sdel_clean.columns]

print("\n=== –û–¢–ß–ï–¢ –ü–û –î–ê–¢–ê–ú (–î–û –§–ò–õ–¨–¢–†–ê–¶–ò–ò) ===")
for col in all_date_cols:
    # 1. –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —Å–∫–æ–ª—å–∫–æ –±—ã–ª–æ –ø—É—Å—Ç—ã—Ö –¥–æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
    na_before = sdel_clean[col].isna().sum()
    
    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å dayfirst=True (–†–æ—Å—Å–∏–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –î–î.–ú–ú.–ì–ì–ì–ì)
    # errors='coerce' –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –º—É—Å–æ—Ä –≤ NaT, –Ω–æ –º—ã —ç—Ç–æ –æ—Ç—Å–ª–µ–¥–∏–º
    sdel_clean[col] = pd.to_datetime(sdel_clean[col], dayfirst=True, errors='coerce')
    
    # 3. –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–ª–æ –ø—É—Å—Ç—ã—Ö
    na_after = sdel_clean[col].isna().sum()
    lost = na_after - na_before
    
    print(f"–ö–æ–ª–æ–Ω–∫–∞ '{col}':")
    if lost > 0:
        print(f"  ‚ùå –ë–ò–¢–´–ô –§–û–†–ú–ê–¢: {lost} –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å (–ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∏—Å—å –≤ NaT).")
    else:
        print(f"  ‚úÖ –í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã.")

# –†–∞—Å—á–µ—Ç —É–¥–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
sdel_clean['cnt_safe'] = sdel_clean['–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫'].replace(0, 1)
sdel_clean['Unit_Area'] = sdel_clean['–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫'] / sdel_clean['cnt_safe']
sdel_clean['Unit_Price'] = sdel_clean['–°—É–º–º–∞ –±—é–¥–∂–µ—Ç–∞'] / sdel_clean['cnt_safe']
sdel_clean['Price_m2'] = sdel_clean['–°—É–º–º–∞ –±—é–¥–∂–µ—Ç–∞'] / sdel_clean['–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫'].replace(0, np.nan)


# === 2. –£–ú–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ü–õ–û–©–ê–î–¨ vs –ö–û–ú–ù–ê–¢–´ ===
mask_area_rooms_outlier = pd.Series(False, index=sdel_clean.index)
unique_rooms = sorted(sdel_clean['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç'].unique())

print("\n=== –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–õ–û–©–ê–î–ï–ô ===")
for room_cnt in unique_rooms:
    idx_room = sdel_clean[sdel_clean['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç'] == room_cnt].index
    if len(idx_room) == 0: continue
    
    subset_areas = sdel_clean.loc[idx_room, 'Unit_Area']
    Q1 = subset_areas.quantile(0.25)
    Q3 = subset_areas.quantile(0.75)
    IQR = Q3 - Q1
    lower = max(Q1 - (IQR_THRESHOLD * IQR), 10.0)
    upper = Q3 + (IQR_THRESHOLD * IQR)
    
    bad_indices = subset_areas[(subset_areas < lower) | (subset_areas > upper)].index
    mask_area_rooms_outlier.loc[bad_indices] = True

# === 3. –û–°–¢–ê–õ–¨–ù–´–ï –§–ò–õ–¨–¢–†–´ ===
Q1_p = sdel_clean['Price_m2'].quantile(0.25)
Q3_p = sdel_clean['Price_m2'].quantile(0.75)
IQR_p = Q3_p - Q1_p
mask_price_outlier = (sdel_clean['Price_m2'] < (Q1_p - 1.5*IQR_p)) | (sdel_clean['Price_m2'] > (Q3_p + 1.5*IQR_p))

mask_cheap = sdel_clean['Unit_Price'] < MIN_PRICE_UNIT

# === 4. –°–ë–û–†–ö–ê –ò–¢–û–ì–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–ê ===
total_mask = mask_area_rooms_outlier | mask_price_outlier | mask_cheap 
sdel_final = sdel_clean[~total_mask].copy()

# === 5. –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ ===
print("\n" + "="*60)
print(f"–ò–¢–û–ì–ò –û–ß–ò–°–¢–ö–ò (–ë—ã–ª–æ: {len(sdel_clean)} -> –°—Ç–∞–ª–æ: {len(sdel_final)})")
print("-" * 60)
    
print("-" * 60)
print(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ –≤—Å–µ–≥–æ: {total_mask.sum()}")
sdel_final.drop(columns=['cnt_safe'], inplace=True, errors='ignore')


import pandas as pd
import numpy as np
from datetime import timedelta
import warnings

warnings.filterwarnings('ignore')

# ============================================================
# 1) –§–£–ù–ö–¶–ò–Ø –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì–ê (ETL)
# ============================================================

def process_real_estate_data(
    proj: str,
    deals: str,
    bank_percentile_range: tuple = (0, 100),
    bank_metric_for_filtering: str = "sq_meters"  # 'count', 'sq_meters', 'money'
):
    """
    ETL –¥–ª—è bnMAP / –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∏.

    –í–ê–ñ–ù–û:
    1) Sellout —Å—á–∏—Ç–∞–µ—Ç—Å—è –°–¢–†–û–ì–û –ø–æ –∏–ø–æ—Ç–µ—á–Ω—ã–º —Å–¥–µ–ª–∫–∞–º.
    2) –í –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –ö–æ–º—Ñ–æ—Ä—Ç-–∫–ª–∞—Å—Å.
       –ü–æ–¥ "–ö–æ–º—Ñ–æ—Ä—Ç" –ø–æ–Ω–∏–º–∞–µ—Ç—Å—è: –ö–æ–º—Ñ–æ—Ä—Ç / –∫–æ–º—Ñ–æ—Ä—Ç / –∫–æ–º—Ñ–æ—Ä—Ç+ / –∫–æ–º—Ñ–æ—Ä—Ç –∫–ª–∞—Å—Å / –∫–ª–∞—Å—Å –∫–æ–º—Ñ–æ—Ä—Ç –∏ —Ç.–ø.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    df_ml : pd.DataFrame  (–∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å –¥–∞–ª—å–Ω–µ–π—à–∏–º –∞–Ω–∞–ª–∏–∑–æ–º —á–µ—Ä–µ–∑ rename)
    bank_stats : pd.DataFrame
    report : dict
    """

    print("üöÄ –ó–ê–ü–£–°–ö –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–• (–†–ï–ñ–ò–ú: –ò–ü–û–¢–ï–ß–ù–´–ô SELLOUT)")
    print(f"   –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–∞–Ω–∫–æ–≤-—Ñ–∏—á–µ–π: –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏ {bank_percentile_range}, –º–µ—Ç—Ä–∏–∫–∞ '{bank_metric_for_filtering}'")
    print("   –§–∏–ª—å—Ç—Ä –∫–ª–∞—Å—Å–æ–≤: –û–°–¢–ê–í–õ–Ø–ï–ú –¢–û–õ–¨–ö–û '–ö–æ–º—Ñ–æ—Ä—Ç' (–≤–∫–ª—é—á–∞—è '–ö–æ–º—Ñ–æ—Ä—Ç+', '–ö–æ–º—Ñ–æ—Ä—Ç –∫–ª–∞—Å—Å', '–∫–ª–∞—Å—Å –∫–æ–º—Ñ–æ—Ä—Ç')")

    # =========================================================
    # 0) helpers
    # =========================================================
    def _strip_columns(df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df.columns = [str(c).strip() for c in df.columns]
        return df

    def clean_numeric_col(df, col_name):
        if col_name in df.columns:
            val = df[col_name].astype(str)
            val = (
                val.str.replace("\u00a0", "", regex=False)
                   .str.replace(" ", "", regex=False)
                   .str.replace(",", ".", regex=False)
            )
            return pd.to_numeric(val, errors="coerce").fillna(0)
        return df[col_name] if col_name in df.columns else 0

    def norm_class_to_key(x) -> str:
        if pd.isna(x):
            return ""
        s = str(x).strip().lower()

        # –ø—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–æ–±–µ–ª—ã
        for ch in ["\u00a0", "\t", "\n", "\r"]:
            s = s.replace(ch, " ")
        s = " ".join(s.split())

        # —É–±—Ä–∞—Ç—å "–∫–ª–∞—Å—Å" –∏ —à—É–º
        s = s.replace("–∫–ª–∞—Å—Å", " ")
        for ch in ["+", "-", "_", "/", "\\", "|", "‚Äî", "‚Äì", "(", ")", "[", "]", "{", "}", ".", ",", ":", ";"]:
            s = s.replace(ch, " ")
        s = " ".join(s.split())

        # –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Å–ª–æ–≤–æ "–∫–æ–º—Ñ–æ—Ä—Ç" -> –∫–æ–º—Ñ–æ—Ä—Ç
        if "–∫–æ–º—Ñ–æ—Ä—Ç" in s:
            return "–∫–æ–º—Ñ–æ—Ä—Ç"
        return s

    def find_class_col(df: pd.DataFrame):
        candidates = [
            "–ö–ª–∞—Å—Å –ø—Ä–æ–µ–∫—Ç–∞", "–ö–ª–∞—Å—Å", "–ö–ª–∞—Å—Å –∂–∏–ª—å—è", "–ö–ª–∞—Å—Å –ñ–ö", "–ö–ª–∞—Å—Å –æ–±—ä–µ–∫—Ç–∞",
            "–ö–ª–∞—Å—Å_–ø—Ä–æ–µ–∫—Ç–∞", "–ö–ª–∞—Å—Å–ü—Ä–æ–µ–∫—Ç–∞"
        ]
        cols = list(df.columns)
        # 1) —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for c in candidates:
            if c in cols:
                return c
        # 2) ‚Äú–ø–æ—Ö–æ–∂–µ–µ‚Äù –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ
        low_map = {c: c.lower() for c in cols}
        for c in cols:
            lc = low_map[c]
            if "–∫–ª–∞—Å—Å" in lc and ("–ø—Ä–æ–µ–∫—Ç" in lc or "–∂–∫" in lc or "–∂–∏–ª—å" in lc):
                return c
        for c in cols:
            lc = low_map[c]
            if "–∫–ª–∞—Å—Å" in lc:
                return c
        return None

    def find_project_col(df: pd.DataFrame):
        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–µ—Å–ª–∏ –≤ –∫–∞–∫–æ–º-—Ç–æ —Ñ–∞–π–ª–µ "–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö")
        if "–ü—Ä–æ–µ–∫—Ç" in df.columns:
            return "–ü—Ä–æ–µ–∫—Ç"
        if "–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö" in df.columns:
            return "–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö"
        return None

    proj = _strip_columns(proj)
    deals = _strip_columns(deals)

    # =========================================================
    # 2) filter class in proj (comfort only)
    # =========================================================
    class_col_proj = find_class_col(proj)
    if class_col_proj is None:
        print("‚ö†Ô∏è –ù–ï –ù–ê–®–Å–õ –∫–æ–ª–æ–Ω–∫—É –∫–ª–∞—Å—Å–∞ –≤ proj. –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª–∞—Å—Å—É –ù–ï –ø—Ä–∏–º–µ–Ω—ë–Ω.")
    else:
        n_before = len(proj)
        proj["_class_norm"] = proj[class_col_proj].apply(norm_class_to_key)
        print("\nüìå –ü–†–û–í–ï–†–ö–ê –ö–õ–ê–°–°–ê –í PROJ (–¢–û–ü-20):")
        try:
            print(proj[class_col_proj].astype(str).value_counts().head(20))
        except Exception:
            pass
        proj = proj[proj["_class_norm"] == "–∫–æ–º—Ñ–æ—Ä—Ç"].copy()
        proj.drop(columns=["_class_norm"], inplace=True)
        print(f"‚úÖ –§–∏–ª—å—Ç—Ä proj –ø–æ –∫–ª–∞—Å—Å—É: –±—ã–ª–æ {n_before}, —Å—Ç–∞–ª–æ {len(proj)} (–ö–æ–º—Ñ–æ—Ä—Ç)")

    # –µ—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ proj –ø—É—Å—Ç–æ–π ‚Äî —Å–º—ã—Å–ª–∞ –Ω–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å
    if proj.empty:
        print("‚õî –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –∫–ª–∞—Å—Å—É proj –ø—É—Å—Ç–æ–π. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–∑–≤–∞–Ω–∏—è/–∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–µ –∫–ª–∞—Å—Å–∞.")
        return pd.DataFrame(), pd.DataFrame(), {"total": 0, "success": 0, "skipped_young": 0, "skipped_no_sales": 0, "dropped_bad_so": 0}

    # =========================================================
    # 3) numeric cleaning
    # =========================================================
    for col in [
        "–û–±—â–∞—è –ø—Ä–æ–µ–∫—Ç–Ω–∞—è –ø–ª–æ—â–∞–¥—å",
        "–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫",
        "–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫",
        "–°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–æ–∫",
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ—Ç–æ–≤",
    ]:
        if col in proj.columns:
            proj[col] = clean_numeric_col(proj, col)
        if col in deals.columns:
            deals[col] = clean_numeric_col(deals, col)

    if "–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫" not in deals.columns:
        deals["–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫"] = 1

    # =========================================================
    # 4) dates
    # =========================================================
    if "–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ (–º–µ—Å—è—Ü.–≥–æ–¥)" not in deals.columns:
        raise ValueError("–í deals –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ (–º–µ—Å—è—Ü.–≥–æ–¥)'")

    deals["dt_deal"] = pd.to_datetime(deals["–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ (–º–µ—Å—è—Ü.–≥–æ–¥)"], dayfirst=True, errors="coerce")
    mask_date_na = deals["dt_deal"].isna()
    if mask_date_na.any():
        deals.loc[mask_date_na, "dt_deal"] = pd.to_datetime(
            "01." + deals.loc[mask_date_na, "–î–∞—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ (–º–µ—Å—è—Ü.–≥–æ–¥)"].astype(str),
            dayfirst=True,
            errors="coerce",
        )
    deals = deals.dropna(subset=["dt_deal"]).copy()

    # =========================================================
    # 5) ids / project names
    # =========================================================
    for df in [proj, deals]:
        if "ID –∫–æ—Ä–ø—É—Å–∞" not in df.columns:
            raise ValueError("–ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'ID –∫–æ—Ä–ø—É—Å–∞' –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–∞–π–ª–æ–≤")
        df["ID –∫–æ—Ä–ø—É—Å–∞"] = df["ID –∫–æ—Ä–ø—É—Å–∞"].astype(str).str.replace(r"\.0$", "", regex=True).str.strip()

        proj_col = find_project_col(df)
        if proj_col is not None:
            df[proj_col] = df[proj_col].astype(str).str.strip()
            if proj_col != "–ü—Ä–æ–µ–∫—Ç":
                df.rename(columns={proj_col: "–ü—Ä–æ–µ–∫—Ç"}, inplace=True)

    # =========================================================
    # 6) merge deals <- proj mapping (—Ç–æ–ª—å–∫–æ –∫–æ–º—Ñ–æ—Ä—Ç!)
    # =========================================================
    class_col_proj = find_class_col(proj)
    cols_map = ["ID –∫–æ—Ä–ø—É—Å–∞", "–ü—Ä–æ–µ–∫—Ç"]
    if class_col_proj is not None and class_col_proj in proj.columns:
        cols_map.append(class_col_proj)

    corpus_map = proj[cols_map].drop_duplicates().set_index("ID –∫–æ—Ä–ø—É—Å–∞")
    n_before_deals = len(deals)
    deals = deals.merge(corpus_map, on="ID –∫–æ—Ä–ø—É—Å–∞", how="inner")  # INNER = –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–µ–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–µ –∫–æ—Ä–ø—É—Å–∞
    print(f"‚úÖ deals –ø–æ—Å–ª–µ INNER –º—ë—Ä–∂–∞ –ø–æ –∫–æ—Ä–ø—É—Å–∞–º (—Ç–æ–ª—å–∫–æ –ö–æ–º—Ñ–æ—Ä—Ç –∫–æ—Ä–ø—É—Å–∞): –±—ã–ª–æ {n_before_deals}, —Å—Ç–∞–ª–æ {len(deals)}")

    # === FIX: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤ deals –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ "–ü—Ä–æ–µ–∫—Ç" ===
    if "–ü—Ä–æ–µ–∫—Ç" not in deals.columns:
        if "–ü—Ä–æ–µ–∫—Ç_y" in deals.columns:
            deals["–ü—Ä–æ–µ–∫—Ç"] = deals["–ü—Ä–æ–µ–∫—Ç_y"]
        elif "–ü—Ä–æ–µ–∫—Ç_x" in deals.columns:
            deals["–ü—Ä–æ–µ–∫—Ç"] = deals["–ü—Ä–æ–µ–∫—Ç_x"]
        else:
            raise ValueError("‚ùå –ü–æ—Å–ª–µ merge –≤ deals –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ü—Ä–æ–µ–∫—Ç'")

    # –ø–æ–¥—á–∏—Å—Ç–∏–º —Ö–≤–æ—Å—Ç—ã
    deals.drop(columns=[c for c in ["–ü—Ä–æ–µ–∫—Ç_x", "–ü—Ä–æ–µ–∫—Ç_y"] if c in deals.columns],
            inplace=True, errors="ignore")

    # =========================================================
    # 7) final safety: class filter in deals (–µ—Å–ª–∏ –µ—Å—Ç—å)
    # =========================================================
    class_col_deals = find_class_col(deals)
    if class_col_deals is not None:
        n_before = len(deals)
        deals["_class_norm"] = deals[class_col_deals].apply(norm_class_to_key)
        deals = deals[deals["_class_norm"] == "–∫–æ–º—Ñ–æ—Ä—Ç"].copy()
        deals.drop(columns=["_class_norm"], inplace=True)
        print(f"‚úÖ –§–∏–ª—å—Ç—Ä deals –ø–æ –∫–ª–∞—Å—Å—É: –±—ã–ª–æ {n_before}, —Å—Ç–∞–ª–æ {len(deals)} (–ö–æ–º—Ñ–æ—Ä—Ç)")

    # =========================================================
    # 8) mortgage + banks
    # =========================================================
    mortgage_flags = ["–¥–∞", "yes", "true", "1", "–∏–ø–æ—Ç–µ–∫–∞"]

    if "–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞" not in deals.columns:
        deals["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"] = "–ù–µ —É–∫–∞–∑–∞–Ω"
    deals["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"] = deals["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"].fillna("–†–∞—Å—Å—Ä–æ—á–∫–∞/–ö—ç—à").astype(str).str.strip()

    # --- –ê–ù–ê–õ–ò–ó –ë–ê–ù–ö–û–í ---
    grp_cols = {"–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫": "sum", "–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫": "sum"}
    if "–°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–æ–∫" in deals.columns:
        grp_cols["–°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–æ–∫"] = "sum"

    bank_stats = deals.groupby("–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞").agg(grp_cols).reset_index()
    bank_stats = bank_stats.rename(columns={
        "–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫": "count",
        "–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫": "sq_meters",
        "–°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–æ–∫": "money",
    })
    if "money" not in bank_stats.columns:
        bank_stats["money"] = 0

    total_sq = bank_stats["sq_meters"].sum()
    bank_stats["share_sq_meters"] = (bank_stats["sq_meters"] / total_sq * 100) if total_sq > 0 else 0

    target_metric = bank_metric_for_filtering if bank_metric_for_filtering in bank_stats.columns else "sq_meters"
    threshold_low = np.percentile(bank_stats[target_metric], bank_percentile_range[0])
    threshold_high = np.percentile(bank_stats[target_metric], bank_percentile_range[1])

    bank_stats["is_selected"] = (bank_stats[target_metric] >= threshold_low) & (bank_stats[target_metric] <= threshold_high)
    bank_stats["bank_weight_score"] = np.log1p(bank_stats["sq_meters"])

    selected_banks = bank_stats[bank_stats["is_selected"]]["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"].tolist()
    bank_weights_dict = bank_stats.set_index("–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞")["bank_weight_score"].to_dict()

    # =========================================================
    # 9) macro
    # =========================================================
    key_rate_data = [
        ("2013-09-13", "2014-03-02", 5.50), ("2014-03-03", "2014-04-24", 7.00), ("2014-04-25", "2014-07-27", 7.50),
        ("2014-07-28", "2014-11-04", 8.00), ("2014-11-05", "2014-12-11", 9.50), ("2014-12-12", "2014-12-15", 10.50),
        ("2014-12-16", "2015-02-01", 17.00), ("2015-02-02", "2015-03-15", 15.00), ("2015-03-16", "2015-05-04", 14.00),
        ("2015-05-05", "2015-06-15", 12.50), ("2015-06-16", "2015-08-02", 11.50), ("2015-08-03", "2016-06-13", 11.00),
        ("2016-06-14", "2016-09-18", 10.50), ("2016-09-19", "2017-03-26", 10.00), ("2017-03-27", "2017-05-01", 9.75),
        ("2017-05-02", "2017-06-18", 9.25), ("2017-06-19", "2017-09-17", 9.00), ("2017-09-18", "2017-10-29", 8.50),
        ("2017-10-30", "2017-12-17", 8.25), ("2017-12-18", "2018-02-11", 7.75), ("2018-02-12", "2018-03-25", 7.50),
        ("2018-03-26", "2018-09-16", 7.25), ("2018-09-17", "2018-12-16", 7.50), ("2018-12-17", "2019-06-16", 7.75),
        ("2019-06-17", "2019-07-28", 7.50), ("2019-07-29", "2019-09-08", 7.25), ("2019-09-09", "2019-10-27", 7.00),
        ("2019-10-28", "2019-12-15", 6.50), ("2019-12-16", "2020-02-09", 6.25), ("2020-02-10", "2020-04-26", 6.00),
        ("2020-04-27", "2020-06-21", 5.50), ("2020-06-22", "2020-07-26", 4.50), ("2020-07-27", "2021-03-21", 4.25),
        ("2021-03-22", "2021-04-25", 4.50), ("2021-04-26", "2021-06-14", 5.00), ("2021-06-15", "2021-07-25", 5.50),
        ("2021-07-26", "2021-09-12", 6.50), ("2021-09-13", "2021-10-24", 6.75), ("2021-10-25", "2021-12-19", 7.50),
        ("2021-12-20", "2022-02-13", 8.50), ("2022-02-14", "2022-02-27", 9.50), ("2022-02-28", "2022-04-10", 20.00),
        ("2022-04-11", "2022-05-03", 17.00), ("2022-05-04", "2022-05-26", 14.00), ("2022-05-27", "2022-06-13", 11.00),
        ("2022-06-14", "2022-07-24", 9.50), ("2022-07-25", "2022-09-18", 8.00), ("2022-09-19", "2022-12-31", 7.50),
        ("2023-01-01", "2023-07-26", 7.50), ("2023-07-27", "2023-08-14", 8.50), ("2023-08-15", "2023-09-17", 12.00),
        ("2023-09-18", "2023-10-29", 13.00), ("2023-10-30", "2023-12-17", 15.00), ("2023-12-18", "2024-07-28", 16.00),
        ("2024-07-29", "2024-09-15", 18.00), ("2024-09-16", "2024-12-27", 19.00), ("2024-12-28", "2025-06-08", 21.00),
    ]

    macro_range = pd.date_range(start="2013-09-13", end="2026-01-01", freq="D")
    macro_df = pd.DataFrame(index=macro_range)
    macro_df["key_rate"] = np.nan
    macro_df["is_subsidy"] = 0

    for start, end, rate in key_rate_data:
        mask = (macro_df.index >= pd.to_datetime(start)) & (macro_df.index <= pd.to_datetime(end))
        macro_df.loc[mask, "key_rate"] = rate

    macro_df["key_rate"] = macro_df["key_rate"].ffill()
    macro_df.loc[(macro_df.index >= "2020-04-17") & (macro_df.index < "2024-07-01"), "is_subsidy"] = 1
    macro_monthly = macro_df["key_rate"].resample("MS").mean()

    def get_macro_features(start_date, end_date):
        subset_daily = macro_df[(macro_df.index >= start_date) & (macro_df.index <= end_date)]
        if subset_daily.empty:
            return np.nan, np.nan, 0, np.nan
        kr_start = subset_daily["key_rate"].iloc[0]
        kr_spread = subset_daily["key_rate"].max() - subset_daily["key_rate"].min()
        sub_share = subset_daily["is_subsidy"].mean()
        subset_monthly = macro_monthly[(macro_monthly.index >= start_date) & (macro_monthly.index <= end_date)]
        kr_mean_monthly = subset_daily["key_rate"].mean() if subset_monthly.empty else subset_monthly.mean()
        return kr_start, kr_spread, sub_share, kr_mean_monthly

    # =========================================================
    # 10) build dataset
    # =========================================================
    corpus_starts = deals.groupby("ID –∫–æ—Ä–ø—É—Å–∞")["dt_deal"].min().reset_index().rename(columns={"dt_deal": "corpus_start"})
    proj = proj.merge(corpus_starts, on="ID –∫–æ—Ä–ø—É—Å–∞", how="left")

    temp_proj_starts = proj.groupby("–ü—Ä–æ–µ–∫—Ç")["corpus_start"].min().reset_index().rename(columns={"corpus_start": "project_start_implied"})
    proj = proj.merge(temp_proj_starts, on="–ü—Ä–æ–µ–∫—Ç", how="left")
    proj["corpus_start"] = proj["corpus_start"].fillna(proj["project_start_implied"])

    proj_starts = proj.groupby("–ü—Ä–æ–µ–∫—Ç")["corpus_start"].min().reset_index().rename(columns={"corpus_start": "project_start"})
    MAX_DATE = deals["dt_deal"].max()

    data_list = []
    projects_list = proj_starts["–ü—Ä–æ–µ–∫—Ç"].unique()

    stats_cnt = {"total": int(len(projects_list)), "success": 0, "skipped_young": 0, "skipped_no_sales": 0, "dropped_bad_so": 0}
    print(f"\nüîÑ –û–ë–†–ê–ë–û–¢–ö–ê –ü–†–û–ï–ö–¢–û–í ({len(projects_list)} —à—Ç)...")

    class_col_proj = find_class_col(proj)

    for project in projects_list:
        t0 = proj_starts.loc[proj_starts["–ü—Ä–æ–µ–∫—Ç"] == project, "project_start"].values[0]
        t0 = pd.to_datetime(t0)
        if pd.isna(t0):
            continue

        t_end_y1 = t0 + timedelta(days=365)
        if (MAX_DATE - t0).days < 365:
            stats_cnt["skipped_young"] += 1
            continue

        valid_corp_y1 = proj[(proj["–ü—Ä–æ–µ–∫—Ç"] == project) & (proj["corpus_start"] <= t_end_y1)]
        area_planned_y1 = valid_corp_y1["–û–±—â–∞—è –ø—Ä–æ–µ–∫—Ç–Ω–∞—è –ø–ª–æ—â–∞–¥—å"].sum()

        # –õ–û–¢–´ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ—Ç–æ–≤" in valid_corp_y1.columns:
            lots_planned_y1 = valid_corp_y1["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ—Ç–æ–≤"].sum()
        else:
            lots_planned_y1 = np.nan

        mask_sales_y1 = (deals["–ü—Ä–æ–µ–∫—Ç"] == project) & (deals["dt_deal"] >= t0) & (deals["dt_deal"] <= t_end_y1)
        deals_subset_y1 = deals[mask_sales_y1]

        # –∏–ø–æ—Ç–µ–∫–∞
        if "–ò–ø–æ—Ç–µ–∫–∞" not in deals_subset_y1.columns:
            raise ValueError("–í deals –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ò–ø–æ—Ç–µ–∫–∞' ‚Äî –±–µ–∑ –Ω–µ—ë –∏–ø–æ—Ç–µ—á–Ω—ã–π sellout –Ω–µ –ø–æ—Å—á–∏—Ç–∞—Ç—å.")
        mortgage_deals_y1 = deals_subset_y1[deals_subset_y1["–ò–ø–æ—Ç–µ–∫–∞"].astype(str).str.lower().isin(mortgage_flags)]

        sales_y1 = mortgage_deals_y1["–°—É–º–º–∞—Ä–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å–¥–µ–ª–æ–∫"].sum()
        count_y1 = int(len(mortgage_deals_y1))  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫

        if sales_y1 <= 0 or area_planned_y1 <= 0:
            stats_cnt["skipped_no_sales"] += 1
            continue

        kr_start, kr_spread, sub_share, kr_mean = get_macro_features(t0, t_end_y1)
        mort_share = (len(mortgage_deals_y1) / len(deals_subset_y1)) if len(deals_subset_y1) > 0 else 0

        banks_in_project = mortgage_deals_y1[mortgage_deals_y1["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"].isin(selected_banks)]["–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞"].unique()
        num_banks_filtered = int(len(banks_in_project))
        bank_weighted_index = float(sum(bank_weights_dict.get(b, 0) for b in banks_in_project))

        so_val_pct = float((sales_y1 / area_planned_y1) * 100)

        # –∫–ª–∞—Å—Å –ø—Ä–æ–µ–∫—Ç–∞ (–∏–∑ proj, –Ω–æ –æ–Ω —É–∂–µ –∫–æ–º—Ñ–æ—Ä—Ç)
        if class_col_proj is not None and class_col_proj in proj.columns:
            p_class = proj.loc[proj["–ü—Ä–æ–µ–∫—Ç"] == project, class_col_proj].iloc[0]
        else:
            p_class = "–ö–æ–º—Ñ–æ—Ä—Ç"

        data_list.append({
            "Project": project,
            "Class": p_class,
            "Year_Num": 1,
            "Planned_Area": float(area_planned_y1),
            "Planned_Lots": float(lots_planned_y1) if pd.notna(lots_planned_y1) else np.nan,
            "Sold_Area": float(sales_y1),
            "Deals_Count": int(count_y1),
            "Sellout_Pct": float(so_val_pct),
            "KR_Start": kr_start,
            "KR_Spread": kr_spread,
            "KR_Mean": kr_mean,
            "Subsidy_Share": sub_share,
            "Mortgage_Share": float(mort_share),
            "Num_Banks_Filtered": int(num_banks_filtered),
            "Bank_Index_Weighted": float(bank_weighted_index),
            "Log_Area": float(np.log1p(area_planned_y1)),
        })

    df_ml = pd.DataFrame(data_list)

    if not df_ml.empty:
        n_before = len(df_ml)
        df_ml = df_ml[df_ml["Sellout_Pct"] <= 100].copy()
        stats_cnt["dropped_bad_so"] = int(n_before - len(df_ml))
        stats_cnt["success"] = int(len(df_ml))

    print("\n‚úÖ –ì–û–¢–û–í–û!")
    print(f"   –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç—Ä–æ–∫ –¥–ª—è ML: {len(df_ml)}")
    print(f"   –û—à–∏–±–æ–∫ Sellout>100%: {stats_cnt['dropped_bad_so']}")

    if "Class" in df_ml.columns and not df_ml.empty:
        print("\nüìå –ö–õ–ê–°–°–´ –í –ò–¢–û–ì–ï df_ml (value_counts):")
        print(df_ml["Class"].astype(str).value_counts().head(20))

    return df_ml, bank_stats, stats_cnt


# ============================================================
# 2) –ò–ú–ü–û–†–¢–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô (–ö–ê–ö –£ –¢–ï–ë–Ø)
# ============================================================

import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy import stats

warnings.filterwarnings('ignore')

# ============================================================
# 0. –ù–ê–°–¢–†–û–ô–ö–ò
# ============================================================

sns.set(style="whitegrid", palette="muted")
plt.rcParams["figure.figsize"] = (10, 6)

print("========================================================")
print("–°–¢–ê–†–¢ –ê–ù–ê–õ–ò–ó–ê bnMAP.pro ‚Äî –ù–û–í–´–ô –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì")
print("========================================================\n")

# –§–∞–π–ª—ã (–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–∏ –ª–µ–∂–∞—Ç –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ)
FILE_PROJ = "–ü—Ä–æ–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ_2025-11-25.xlsx"
FILE_DEALS = "–°–¥–µ–ª–∫–∏_2025-11-25.xlsx"

# ============================================================
# 2. –ü–û–õ–£–ß–ï–ù–ò–ï –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê
# ============================================================

# 2.1 –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
df_ml, bank_stats, report = process_real_estate_data(
    proj,
    sdel_final,
    bank_percentile_range=(0, 100)  # –ë–µ—Ä–µ–º –≤—Å–µ –±–∞–Ω–∫–∏
)

# –∑–∞—â–∏—Ç–Ω–æ: –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –¥–∞–ª—å—à–µ –≥—Ä–∞—Ñ–∏–∫–∏ —É–ø–∞–¥—É—Ç ‚Äî –Ω–æ —Ç—ã –ø—Ä–æ—Å–∏–ª ‚Äú–±–µ–∑ –æ—à–∏–±–æ–∫‚Äù
# –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º
if df_ml.empty:
    print("\n‚õî df_ml –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤. –î–∞–ª—å—à–µ –∞–Ω–∞–ª–∏–∑ –Ω–µ —Å—Ç—Ä–æ–∏–º, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å —Å KeyError.")
    raise SystemExit(0)

# 2.2 –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞–ª–∏ —Å –∫–æ–¥–æ–º –∞–Ω–∞–ª–∏–∑–∞
final = df_ml.rename(columns={
    "Project": "–ü—Ä–æ–µ–∫—Ç",
    "Planned_Area": "planned_area",
    "Planned_Lots": "planned_lots",
    "Sold_Area": "sold_area_12m",
    "Deals_Count": "deals_count_12m",
    "Num_Banks_Filtered": "num_banks_12m",
    "Sellout_Pct": "sellout_12m_pct"
}).copy()

final["sellout_12m"] = final["sellout_12m_pct"] / 100.0

# 2.3 –î–æ—Ä–∞—Å—á–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–æ–≤
final["log_planned_area"] = np.log1p(final["planned_area"])
final["log_deals_12m"] = np.log1p(final["deals_count_12m"])

print("\n=== –ò–¢–û–ì–û–í–´–ô DATAFRAME –ü–û–°–õ–ï –ü–†–ê–í–ò–õ–¨–ù–û–ì–û ETL (–ü–ï–†–í–´–ï 5) ===")
print(final.head())

# 2.4 –ü–û–î–¢–Ø–ì–ò–í–ê–ï–ú "–û–ö–†–£–ì" (–¥–ª—è Robustness Check –≤ –∫–æ–Ω—Ü–µ)
try:
    raw_deals = pd.read_excel(FILE_DEALS)
    raw_deals.columns = [str(c).strip() for c in raw_deals.columns]

    col_proj_raw = "–ü—Ä–æ–µ–∫—Ç" if "–ü—Ä–æ–µ–∫—Ç" in raw_deals.columns else ("–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö" if "–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö" in raw_deals.columns else None)
    col_geo = "–û–∫—Ä—É–≥"

    if col_proj_raw is not None and col_geo in raw_deals.columns:
        geo_map = raw_deals.groupby(col_proj_raw)[col_geo].agg(
            lambda x: x.mode()[0] if not x.mode().empty else np.nan
        ).reset_index()

        geo_map = geo_map.rename(columns={col_proj_raw: "–ü—Ä–æ–µ–∫—Ç"})
        final = final.merge(geo_map, on="–ü—Ä–æ–µ–∫—Ç", how="left")
        print("-> –î–∞–Ω–Ω—ã–µ –ø–æ –û–∫—Ä—É–≥–∞–º —É—Å–ø–µ—à–Ω–æ –ø–æ–¥—Ç—è–Ω—É—Ç—ã.")
    else:
        print("-> ! –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É '–û–∫—Ä—É–≥' –∏–ª–∏ –∫–æ–ª–æ–Ω–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ —Å–¥–µ–ª–æ–∫.")
except Exception as e:
    print(f"-> –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Ç—è–≥–∏–≤–∞–Ω–∏–∏ –æ–∫—Ä—É–≥–æ–≤: {e}")


# ============================================================
# 8. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø (–û–°–¢–ê–í–õ–ï–ù–û –ò–ó –û–†–ò–ì–ò–ù–ê–õ–ê)
# ============================================================

# Boxplot –¥–ª—è —Å–¥–µ–ª–æ–∫
plt.figure()
sns.boxplot(y=final["deals_count_12m"])
plt.title("Boxplot: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ 12 –º–µ—Å (raw)")
plt.ylabel("deals_count_12m")
plt.tight_layout()
plt.show()

# –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —Å–¥–µ–ª–æ–∫
plt.figure()
sns.histplot(final["deals_count_12m"].dropna(), bins=20, kde=True)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (raw)")
plt.xlabel("deals_count_12m")
plt.tight_layout()
plt.show()

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è log_deals_12m
plt.figure()
sns.histplot(final["log_deals_12m"].dropna(), bins=20, kde=True)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (log1p)")
plt.xlabel("log(1 + deals_count_12m)")
plt.tight_layout()
plt.show()

# ============================================================
# 9. –ì–†–£–ü–ü–´ –ü–†–û–ï–ö–¢–û–í –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£ –ë–ê–ù–ö–û–í
# ============================================================

print("\n=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ë–ê–ù–ö–ê–ú (–ü–ï–†–ï–î –ì–†–£–ü–ü–ò–†–û–í–ö–û–ô) ===")
print(final["num_banks_12m"].describe())

try:
    final["bank_group"] = pd.qcut(
        final["num_banks_12m"],
        q=3,
        labels=["–ú–∞–ª–æ –±–∞–Ω–∫–æ–≤", "–°—Ä–µ–¥–Ω–µ –±–∞–Ω–∫–æ–≤", "–ú–Ω–æ–≥–æ –±–∞–Ω–∫–æ–≤"]
    )
    bank_order = ["–ú–∞–ª–æ –±–∞–Ω–∫–æ–≤", "–°—Ä–µ–¥–Ω–µ –±–∞–Ω–∫–æ–≤", "–ú–Ω–æ–≥–æ –±–∞–Ω–∫–æ–≤"]
    print("\n-> –£—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–ª–∏ –Ω–∞ 3 –≥—Ä—É–ø–ø—ã.")
except ValueError:
    print("\n-> ! –î–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã –¥–ª—è 3 –≥—Ä—É–ø–ø. –î–µ–ª–∏–º –Ω–∞ 2 –≥—Ä—É–ø–ø—ã (–ø–æ –ú–µ–¥–∏–∞–Ω–µ).")
    median_val = final["num_banks_12m"].median()
    final["bank_group"] = np.where(
        final["num_banks_12m"] <= median_val,
        "–ú–∞–ª–æ –±–∞–Ω–∫–æ–≤",
        "–ú–Ω–æ–≥–æ –±–∞–Ω–∫–æ–≤"
    )
    bank_order = ["–ú–∞–ª–æ –±–∞–Ω–∫–æ–≤", "–ú–Ω–æ–≥–æ –±–∞–Ω–∫–æ–≤"]

print("\n=== –ò–¢–û–ì–û–í–´–ï –ì–†–£–ü–ü–´ ===")
print(final["bank_group"].value_counts())

# ============================================================
# 10. –ì–†–ê–§–ò–ö–ò: –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–û–õ–ò–ß–ï–°–¢–í–ê –ë–ê–ù–ö–û–í
# ============================================================

plt.figure()
sns.countplot(x="num_banks_12m", data=final)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∞–Ω–∫–æ–≤ –≤ –ø–µ—Ä–≤—ã–π –≥–æ–¥ (–∏–ø–æ—Ç–µ–∫–∞)")
plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∫—Ä–µ–¥–∏—Ç—É—é—â–∏—Ö")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–µ–∫—Ç–æ–≤")
plt.tight_layout()
plt.show()

plt.figure()
sns.countplot(x="bank_group", data=final, order=bank_order)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∞–Ω–∫–æ–≤")
plt.xlabel("–ì—Ä—É–ø–ø–∞ –ø–æ —á–∏—Å–ª—É –±–∞–Ω–∫–æ–≤")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–µ–∫—Ç–æ–≤")
plt.tight_layout()
plt.show()

# ============================================================
# 11. BOXPLOT: SELLOUT / –°–î–ï–õ–ö–ò vs –ì–†–£–ü–ü–´ –ë–ê–ù–ö–û–í
# ============================================================

plt.figure()
sns.boxplot(
    x="bank_group",
    y="sellout_12m",
    data=final,
    order=bank_order
)
plt.title("–ò–ø–æ—Ç–µ—á–Ω—ã–π sellout –≤ –ø–µ—Ä–≤—ã–π –≥–æ–¥ –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∞–Ω–∫–æ–≤")
plt.xlabel("–ì—Ä—É–ø–ø–∞ –ø–æ —á–∏—Å–ª—É –±–∞–Ω–∫–æ–≤")
plt.ylabel("–ò–ø–æ—Ç–µ—á–Ω—ã–π sellout –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤ (–ø–ª–æ—â–∞–¥—å –ø—Ä–æ–¥–∞–Ω–∞ / –ø—Ä–æ–µ–∫—Ç–Ω–∞—è)")
plt.tight_layout()
plt.show()

plt.figure()
sns.boxplot(
    x="bank_group",
    y="deals_count_12m",
    data=final,
    order=bank_order
)
plt.title("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ –ø–µ—Ä–≤—ã–π –≥–æ–¥ –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∞–Ω–∫–æ–≤")
plt.xlabel("–ì—Ä—É–ø–ø–∞ –ø–æ —á–∏—Å–ª—É –±–∞–Ω–∫–æ–≤")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤")
plt.tight_layout()
plt.show()

# ============================================================
# 12. SCATTER + REGPLOT: RAW vs LOG
# ============================================================

# RAW
plt.figure()
sns.regplot(
    x="num_banks_12m",
    y="deals_count_12m",
    data=final,
    ci=95,
    scatter_kws={"alpha": 0.7}
)
plt.title("–°–≤—è–∑—å: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤ vs –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (raw)")
plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∫—Ä–µ–¥–∏—Ç—É—é—â–∏—Ö –ø—Ä–æ–µ–∫—Ç")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ 12 –º–µ—Å (raw)")
plt.tight_layout()
plt.show()

# LOG
plt.figure()
sns.regplot(
    x="num_banks_12m",
    y="log_deals_12m",
    data=final,
    ci=95,
    scatter_kws={"alpha": 0.7}
)
plt.title("–°–≤—è–∑—å: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤ vs –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (log1p)")
plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∫—Ä–µ–¥–∏—Ç—É—é—â–∏—Ö –ø—Ä–æ–µ–∫—Ç")
plt.ylabel("log(1 + –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ 12 –º–µ—Å)")
plt.tight_layout()
plt.show()

# –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è sellout
plt.figure()
sns.regplot(
    x="num_banks_12m",
    y="sellout_12m",
    data=final,
    ci=95,
    scatter_kws={"alpha": 0.7}
)
plt.title("–°–≤—è–∑—å: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤ vs –∏–ø–æ—Ç–µ—á–Ω—ã–π sellout (12 –º–µ—Å—è—Ü–µ–≤)")
plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∫—Ä–µ–¥–∏—Ç—É—é—â–∏—Ö –ø—Ä–æ–µ–∫—Ç")
plt.ylabel("–ò–ø–æ—Ç–µ—á–Ω—ã–π sellout –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤")
plt.tight_layout()
plt.show()

# ============================================================
# 13. –ö–û–†–†–ï–õ–Ø–¶–ò–ò –ò HEATMAP (—Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –≥–∏–ø–æ—Ç–µ–∑–µ)
# ============================================================

corr_vars = [
    "sellout_12m",
    "deals_count_12m",
    "log_deals_12m",
    "num_banks_12m",
    "planned_area",
    "log_planned_area"
]

corr_df = final[corr_vars].corr()

print("\n=== –ú–ê–¢–†–ò–¶–ê –ö–û–†–†–ï–õ–Ø–¶–ò–ô (–æ–±—â–∞—è) ===")
print(corr_df)

plt.figure(figsize=(10, 8))
sns.heatmap(
    corr_df,
    annot=True,
    fmt=".2f",
    cmap="Blues",
    vmin=-1,
    vmax=1
)
plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–ø–µ—Ä–≤—ã–π –≥–æ–¥, —Ç–æ–ª—å–∫–æ –∏–ø–æ—Ç–µ–∫–∞)")
plt.tight_layout()
plt.show()

focus_vars = ["num_banks_12m", "sellout_12m", "log_deals_12m"]
focus_vars = [v for v in focus_vars if v in final.columns]
corr_focus = final[focus_vars].corr()

print("\n=== –ú–ê–¢–†–ò–¶–ê –ö–û–†–†–ï–õ–Ø–¶–ò–ô (—Ñ–æ–∫—É—Å –Ω–∞ –≥–∏–ø–æ—Ç–µ–∑–µ) ===")
print(corr_focus)

plt.figure(figsize=(5, 4))
sns.heatmap(
    corr_focus,
    annot=True,
    fmt=".2f",
    cmap="Blues",
    vmin=-1,
    vmax=1
)
plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (—Ñ–æ–∫—É—Å –Ω–∞ –≥–∏–ø–æ—Ç–µ–∑–µ)")
plt.tight_layout()
plt.show()

# ============================================================
# 14. –ü–†–û–í–ï–†–ö–ê –ù–ê –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–¨
# ============================================================

X_vif = final[["num_banks_12m", "log_planned_area", "sellout_12m"]].copy()
X_vif = sm.add_constant(X_vif)

vif_data = pd.DataFrame()
vif_data["Variable"] = X_vif.columns
vif_data["VIF"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]

print("\nVIF –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö:")
print(vif_data)

# ============================================================
# 15. –†–ï–ì–†–ï–°–°–ò–ò: –ë–ê–ó–û–í–´–ï –ú–û–î–ï–õ–ò
# ============================================================

reg_df_sellout = final.dropna(subset=["sellout_12m", "num_banks_12m", "log_planned_area"]).copy()
X_sellout = reg_df_sellout[["num_banks_12m", "log_planned_area"]]
X_sellout = sm.add_constant(X_sellout)
y_sellout = reg_df_sellout["sellout_12m"]
model_sellout = sm.OLS(y_sellout, X_sellout).fit()

print("\n========================================================")
print("–†–ï–ì–†–ï–°–°–ò–Ø 1: –ò–ø–æ—Ç–µ—á–Ω—ã–π sellout (12 –º–µ—Å)")
print("–ú–æ–¥–µ–ª—å: sellout_12m ~ num_banks_12m + log_planned_area")
print("--------------------------------------------------------")
print(model_sellout.summary())

# ============================================================
# 16. –ò–¢–û–ì–û–í–´–ô –í–ï–†–î–ò–ö–¢ –ü–û –ì–ò–ü–û–¢–ï–ó–ï –ò POLICY IMPLICATIONS
# ============================================================

beta_sellout = model_sellout.params["num_banks_12m"]
pval_sellout = model_sellout.pvalues["num_banks_12m"]

print("\n========================================================")
print("–ò–¢–û–ì–û–í–´–ô –í–ï–†–î–ò–ö–¢ –ü–û –ì–ò–ü–û–¢–ï–ó–ï (–ø–µ—Ä–≤—ã–π –≥–æ–¥)")
print("--------------------------------------------------------")

if (pval_sellout < 0.05) and (beta_sellout > 0):
    print("1) –î–ª—è –∏–ø–æ—Ç–µ—á–Ω–æ–≥–æ sellout:")
    print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏ num_banks_12m = {beta_sellout:.4f} (p={pval_sellout:.4f}) > 0 –∏ –∑–Ω–∞—á–∏–º.")
    print("   ‚Üí –ü—Ä–∏ –ø—Ä–æ—á–∏—Ö —Ä–∞–≤–Ω—ã—Ö –±–æ–ª—å—à–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –±–∞–Ω–∫–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –∏–ø–æ—Ç–µ—á–Ω—ã–π sellout.")
else:
    print("1) –î–ª—è –∏–ø–æ—Ç–µ—á–Ω–æ–≥–æ sellout —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–≥–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")
    print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç = {beta_sellout:.4f}, p={pval_sellout:.4f}.")

# ============================================================
# BUBBLE-–ì–†–ê–§–ò–ö: sellout vs –∏–ø–æ—Ç–µ—á–Ω–∞—è –ø–ª–æ—â–∞–¥—å
# ============================================================

bubble_df = final.dropna(subset=["sellout_12m", "sold_area_12m",
                                 "deals_count_12m", "num_banks_12m"]).copy()

plt.figure(figsize=(10, 7))

scatter = sns.scatterplot(
    data=bubble_df,
    x="sellout_12m",
    y="sold_area_12m",
    size="deals_count_12m",
    hue="num_banks_12m",
    sizes=(20, 400),
    palette="Blues",
    alpha=0.8,
    edgecolor="black",
    linewidth=0.5
)

plt.title("–°–≤—è–∑—å –º–µ–∂–¥—É –∏–ø–æ—Ç–µ—á–Ω—ã–º sellout –∏ –ø–ª–æ—â–∞–¥—å—é –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤\n"
          "(—Ä–∞–∑–º–µ—Ä ‚Äî —á–∏—Å–ª–æ –∏–ø–æ—Ç–µ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, —Ü–≤–µ—Ç ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–Ω–∫–æ–≤)")
plt.xlabel("–ò–ø–æ—Ç–µ—á–Ω—ã–π sellout –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤ (–¥–æ–ª—è –ø–ª–æ—â–∞–¥–∏)")
plt.ylabel("–ü–ª–æ—â–∞–¥—å –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö –∏–ø–æ—Ç–µ—á–Ω—ã—Ö –ª–æ—Ç–æ–≤ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤, –∫–≤. –º")

handles, labels = scatter.get_legend_handles_labels()
plt.legend(title="–õ–µ–≥–µ–Ω–¥–∞", loc="upper left", bbox_to_anchor=(1.02, 1))

plt.tight_layout()
plt.show()
